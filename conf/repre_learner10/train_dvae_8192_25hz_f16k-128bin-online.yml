# the model aims to use 64Hz code rate.
name: &name dvae_8192_25hz_f16k-128bin-v4
model: extensibletrainer
scale: 1
gpu_ids: [0]
start_step: -1
checkpointing_enabled: false  # <-- Gradient checkpointing. Enable for huge GPU memory savings. Disable for distributed training.
grad_scaler_enabled: false
fp16: &fp16 true # TODO: why does enabling this with 8bit slow down perf??
half_type: &half_type bf16
use_8bit: false
wandb: false  # <-- enable to log to wandb. tensorboard logging is always enabled.
use_tb_logger: true

manual_seed: &manual_seed 37102
mel_bins: &mel_bins 128

online_stat:
  enabled: false
  stat_batches: &stat_batches 10001
  save_dir: &save_dir /home/wumenglin/cache/peoples_speech/dirty/
  stat_cfg:
    type: MeanVarianceOnlineStats
    feature_dim: 1
    n_dim: *mel_bins
    data_key: &stat_key mel
    data_length_key: mel_lengths

audio_process: &audio_process
  sampling_rate: &sr 16000
  mel: &mel_cfg
    mel_fmin: 0
    mel_fmax: 8000
    sampling_rate: *sr
    n_mel_channels: *mel_bins
    filter_length: 400
    hop_length: 160
    win_length: 400
    true_normalization: false
    mel_norm_file: !join [*save_dir, "/", *stat_key, "_stat_", *stat_batches, ".pt"]

dataloaders:
  train:
    # data loader background
    buffer_background: true
    buffer_background_size: 8
    process_background: false
    process_device: -1
    n_workers: 12
    pin_memory: true

    dataset:
      phase: train
      name: peoples_speech_dirty_train
      seed: *manual_seed
      mode: HuggingfaceAudioDataset
      store_type: parquet #json
      data_file: /home/wumenglin/repo-dev/dl-art-school/codes/scripts/peoples_speech/dirty/train*
      cache_dir: /home/wumenglin/cache/peoples_speech/dirty
      min_duration: 5
      max_duration: -1
      sample_duration: 5
      cache_text: false
      cache_audio: mel
      read_keys: ['audio', 'audio_lengths']
      shrink: true
      sorted: true
      carry_filename: false

    sampler:
      batch_size: 1536
      buffer_batch_group: 2
      bucket_batch_volume: 32
      similar_type: null
      last_samples: 'drop'
      shuffle: true
      limited_length_type: null
      length_range: [0, -1]
      copies: 1
      persistent_workers: True
      pad_to_samples: 200
      batch_mode: fixed
      num_buckets: 6
      ## dynamical data sampler
      max_tokens: 54000 # 15 * 768 ^ 1.2 # 34802, 43503 120000/a100
      acc_coeffs: ((1.0, 1.0))
      max_samples: 512

      ## bucketed data sampler
      bucket_max_batch_tokens: 4096
      bucket_min_samples: 1
      bucket_max_samples: 64

    collator:
      mode: Collator
      apply_half: *fp16
      half_type: *half_type

      spec_fn: 'canonical'
      audio_process: *audio_process
      pad_mode: trim
      data_cfg:
        file_names: null
        audio_lengths: null
        audio:
          padding_val: -0.0

  val:
    # data loader background
    buffer_background: true
    buffer_background_size: 2
    process_background: false
    process_device: -1
    n_workers: 12
    pin_memory: true

    dataset:
      phase: val
      name: peoples_speech_dirty_val
      mode: HuggingfaceAudioClipDataset
      store_type:  parquet #json
      data_file: /home/wumenglin/repo-dev/dl-art-school/codes/scripts/peoples_speech/dirty/val*
      cache_dir: /home/wumenglin/cache/peoples_speech/dirty
      min_duration: 5
      max_duration: -1
      sample_duration: 5
      seed: *manual_seed
      cache_text: false
      cache_audio: mel
      phases_ratios: [0.999]
      read_keys: ['audio', 'audio_lengths']
      shrink: true
      sorted: true
      carry_filename: false

    sampler:
      batch_size: 1536
      buffer_batch_group: 2
      bucket_batch_volume: 32
      similar_type: null
      last_samples: 'drop'
      shuffle: true
      limited_length_type: null
      length_range: [0, -1]
      copies: 1
      persistent_workers: True
      pad_to_samples: 200
      batch_mode: fixed
      num_buckets: 6
      ## dynamical data sampler
      max_tokens: 54000 # 15 * 768 ^ 1.2 # 34802, 43503 120000/a100
      acc_coeffs: ((1.0, 1.0))
      max_samples: 512
      ## bucketed data sampler
      bucket_max_batch_tokens: 4096
      bucket_min_samples: 1
      bucket_max_samples: 64

    collator:
      mode: Collator
      apply_half: *fp16
      half_type: *half_type

      spec_fn: 'canonical'
      audio_process: *audio_process
      pad_mode: trim
      data_cfg:
        file_names: null
        audio_lengths: null
        audio:
          padding_val: -0.0

networks:
  generator:
    type: generator
    which_model_G: dvae_representation_learner
    save_freeze: true
    kwargs:
      in_channels: *mel_bins
      codebook_dim: 128
      vae_encoder_codebook: true
      store_run_info: true
      recon_smooth_l1_loss: true
      vae_encoder:
        class_name: model.audio.module.lucidrains_enc_dec.LucidrainsEncoder
        num_layers: 2
        num_resnet_blocks: 3
        hidden_dim: 512
        stride: 2
        kernel_size: 3
        encoder_norm: false
        activation: snake
        positional_dims: 1
      res_encoder: null
      bottleneck:
        class_name: 'model.vqvae.quantizers.JukeboxQuantize'
        codebook_size: 8192
        decay: 0.9
        eps: !!float 1e-5
        debug: false
        max_threshold: -1.0
        min_threshold: 1.0
        new_return_order: false
        norm_type: batch_norm
        dist_type: euclidean
        dynamic_ema_decay: true
      reconstructor:
        class_name: 'model.audio.module.lucidrains_enc_dec.LucidrainsDecoder'
        num_layers: 2
        num_resnet_blocks: 1
        hidden_dim: 512
        out_channels: *mel_bins
        stride: 2
        kernel_size: 3
        activation: snake
        use_transposed_convs: false
        positional_dims: 1
        g_clean_dim: 0
        g_noise_dim: 0
      reconstructor_freeze: false
      global_extractor: null
      seperator: null
      diversity_loss: null
      record_debug_info: true

exp_dir: &exp_dir
  !join [../experiments/, *name]

path:
  #pretrain_model_generator: ../experiments/dvae_2048_32bin_50hz/models/70000_generator.pth
  strict_load: true
  resume_state: !join [*exp_dir, /training_state/]   # <-- Set this to resume from a previous training state.

steps:
  generator:
    training: generator
    clip_grad_eps: 1.0
    check_abnorm_grads: true
    optimizer_params:
      lr: !!float 3e-5
      weight_decay: 0.008
      beta1: 0.9
      beta2: 0.9999
      eps: !!float 1e-08
    injectors:
      to_mel:
        type: canonical_torch_mel_spectrogram
        mel_norm_file: !join [*save_dir, "/", *stat_key, "_stat_", *stat_batches, ".pt"]
        in: audio
        out: actual_mel
        mel_fmin: 0
        mel_fmax: 8000
        sampling_rate: *sr
        n_mel_channels: *mel_bins
        filter_length: 400
        hop_length: 160
        win_length: 400
        true_normalization: false

      gen_inj_train:
        train: true
        type: generator
        generator: generator
        in: [actual_mel]
        out: [recon_loss, commitment_loss, residual_loss, extract_loss, noise_loss, entropy_loss, consistency_loss, tgt, gen, codes] #

    losses:
      recon:
        type: direct
        weight: 2.0
        key: recon_loss
      commitment:
        type: direct
        weight: 0.25
        key: commitment_loss
      # entropy:
      #   type: direct
      #   weight: 0.25
      #   key: entropy_loss
      # consistency:
      #    type: direct
      #    weight: 0.1
      #    key: consistency_loss


train:
  niter: 50000000
  warmup_iter: 1000
  mega_batch_factor: 1    # <-- Gradient accumulation factor. If you are running OOM, increase this to [2,4,8].
  val_freq: 4000

  default_lr_scheme: MultiStepLR
  gen_lr_steps: [7000, 14000, 30000, 60000]
  lr_gamma: 0.5
  manual_seed: *manual_seed

eval:
  output_state: gen
  injectors:
    gen_inj_eval:
      type: generator
      generator: generator
      in: hq
      out: [gen, codebook_commitment_loss]

logger:
  print_freq: 1
  save_checkpoint_freq: 1000
  visuals: [gen, tgt]
  visual_debug_rate: 1000
  visuals_batch_size: 64
  is_mel_spectrogram: true
  disable_state_saving: false


upgrades:
  # Variable: number_of_checkpoints_to_save
  # Description: Define how many checkpoints should be saved on disk (1 checkpoint = pth+ =~ 6.8 GB)
  # Type: integer
  # Value: should be the same value as for number_of_states_to_save
  # smaller than 1 - turn off this option; there is no max value. For Colab use 1 or 2.
  # For Colab use 1 or 2 for gDrive and 5 for instance drive
  # 1 == Leave last saved checkpoint + last saved state (about 6.8 GB).
  # 2 == Leave last 2 saved checkpoints + last saved states (about 2 *~ 6.8 GB =~ 13.6 GB).
  number_of_checkpoints_to_save: 1
  # Variable: number_of_states_to_save
  # Description: Define how many states should be saved on disk (1 state =~ 3.4 GB)
  # if disable_state_saving is set as true this option will be inactive
  # Type: integer
  # Value: should be the same value as for number_of_checkpoints_to_save
  # smaller than 1 - turn off this option; there is no max value.
  # For Colab use 1 or 2 for gDrive and 5 for instance drive
  # 1 == Leave last saved state (about 3.4 GB).
  # 2 == Leave last 2 saved states (about 2 *~ 3.4 GB =~ 6.8 GB).
  number_of_states_to_save: 1
